"""
ì›í‹°ë“œ ì±„ìš©ê³µê³  í†µí•© í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸
=====================================
1ë‹¨ê³„: ì›í‹°ë“œ ì±„ìš©ê³µê³  ë¦¬ìŠ¤íŠ¸ ë° ìƒì„¸ ì •ë³´ í¬ë¡¤ë§
2ë‹¨ê³„: OpenAIë¡œ AI ê´€ë ¨ ê³µê³  ë¶„ë¥˜
3ë‹¨ê³„: ê¸°ì—… ì •ë³´ í¬ë¡¤ë§ ë° ì‚°ì—…ë¶„ì•¼ ë¶„ì„

ëª¨ë“  ë‹¨ê³„ê°€ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ìµœì í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import InvalidSessionIdException, WebDriverException, StaleElementReferenceException

import pandas as pd
import time
import datetime
import warnings
import requests
import json
import re
import os
import sys
from pathlib import Path
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

warnings.filterwarnings('ignore')

# ============================================
# ì„¤ì •
# ============================================
# í¬ë¡¤ë§í•  URLê³¼ ì§ë¬´ ì¹´í…Œê³ ë¦¬ ì„¤ì •
URL = "https://www.wanted.co.kr/wdlist/518/10110"   # ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´
#URL = "https://www.wanted.co.kr/wdlist/518/899"      # íŒŒì´ì¬ ê°œë°œì 
DEFAULT_JOB_CATEGORY = 'ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´'

# ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
MAX_WORKERS_CRAWL = 10   # í¬ë¡¤ë§ ë™ì‹œ ì²˜ë¦¬ ìˆ˜
MAX_WORKERS_OPENAI = 5   # OpenAI API ë™ì‹œ ì²˜ë¦¬ ìˆ˜

# ============================================
# OpenAI API ì„¤ì •
# ============================================
try:
    from openai import OpenAI
except ImportError:
    print("openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. pip install openai ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

try:
    from dotenv import load_dotenv
    env_path = Path(__file__).parent.parent / 'API' / 'config.env'
    if env_path.exists():
        load_dotenv(dotenv_path=env_path)
        print("âœ“ config.env íŒŒì¼ì—ì„œ API í‚¤ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
except:
    pass

api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    config_path = "../API/config.env"
    if os.path.exists(config_path):
        with open(config_path, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip().startswith("OPENAI_API_KEY="):
                    api_key = line.split("=", 1)[1].strip()
                    print("âœ“ config.envì—ì„œ OpenAI API í‚¤ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤.")
                    break

if not api_key:
    print("\ní™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    api_key = input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()

if not api_key:
    print("ì˜¤ë¥˜: API í‚¤ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    sys.exit(1)

openai_client = OpenAI(api_key=api_key)

# ì§„í–‰ ìƒí™© ì¶”ì 
progress_lock = threading.Lock()
completed_count = 0

# íƒ€ì„ìŠ¤íƒ¬í”„
now_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
BASE_PATH = "C://Users//MULTICAMPUS//Desktop//curosr-playground//wanted//"

print("\n" + "=" * 80)
print("ğŸš€ ì›í‹°ë“œ ì±„ìš©ê³µê³  í†µí•© í¬ë¡¤ë§ ìŠ¤í¬ë¦½íŠ¸")
print("=" * 80)
print(f"URL: {URL}")
print(f"ì§ë¬´ ì¹´í…Œê³ ë¦¬: {DEFAULT_JOB_CATEGORY}")
print(f"ë³‘ë ¬ ì²˜ë¦¬: í¬ë¡¤ë§ {MAX_WORKERS_CRAWL}ê°œ, OpenAI {MAX_WORKERS_OPENAI}ê°œ")
print("=" * 80)

total_start_time = time.time()

# ============================================
# [STEP 1] ì›í‹°ë“œ ì±„ìš©ê³µê³  ë¦¬ìŠ¤íŠ¸ ë° ìƒì„¸ ì •ë³´ í¬ë¡¤ë§
# ============================================
print("\n" + "=" * 80)
print("[STEP 1/3] ì›í‹°ë“œ ì±„ìš©ê³µê³  í¬ë¡¤ë§")
print("=" * 80)

# 1-1: Seleniumìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ìŠ¤í¬ë¡¤
print("\n[1-1] ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ìŠ¤í¬ë¡¤ ì¤‘...")

chrome_options = webdriver.ChromeOptions()
chrome_options.add_experimental_option("detach", True)
chrome_options.add_argument('--start-maximized')

driver = webdriver.Chrome(options=chrome_options)
driver.get(URL)
time.sleep(3)

element_xpath = "//div[@data-cy='job-card']/a"
alternative_xpaths = [
    "//div[@data-cy='job-card']/a",
    "//a[contains(@href, '/wd/')]",
    "//div[contains(@class, 'JobCard_JobCard')]/a",
]

wait = WebDriverWait(driver, 20)

element_found = False
for xpath in alternative_xpaths:
    try:
        wait.until(EC.presence_of_element_located((By.XPATH, xpath)))
        element_xpath = xpath
        element_found = True
        print(f"  âœ“ ìš”ì†Œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤")
        break
    except:
        continue

# ìŠ¤í¬ë¡¤ ë‹¤ìš´
SCROLL_PAUSE_TIME = 1.5
try:
    last_height = driver.execute_script("return document.body.scrollHeight")
except:
    driver.quit()
    raise

same_count = 0
while True:
    try:
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(SCROLL_PAUSE_TIME)
        new_height = driver.execute_script("return document.body.scrollHeight")
    except:
        break

    if new_height == last_height:
        same_count += 1
    else:
        same_count = 0

    if same_count >= 2:
        print("  âœ“ ìŠ¤í¬ë¡¤ ì™„ë£Œ")
        break

    last_height = new_height

# ìš”ì†Œ ìˆ˜ì§‘
elements = driver.find_elements(By.XPATH, element_xpath)
print(f"  âœ“ {len(elements)}ê°œ ê³µê³  ë°œê²¬")

# ë¦¬ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘
list_data = []
for idx, e in enumerate(elements):
    try:
        href = e.get_attribute('href')
        if href and href.startswith('/'):
            href = f"https://www.wanted.co.kr{href}"
        
        parent_div = e.find_element(By.XPATH, "./..")
        try:
            button = parent_div.find_element(By.XPATH, ".//button[@data-attribute-id='position__bookmark__click']")
            job_category_id = button.get_attribute('data-job-category-id') or ''
            company_id = button.get_attribute('data-company-id') or ''
            company_name = button.get_attribute('data-company-name') or ''
            position_name = button.get_attribute('data-position-name') or ''
            position_id = button.get_attribute('data-position-id') or ''
        except:
            job_category_id = company_id = company_name = position_name = position_id = ''
        
        if href:
            list_data.append({
                'job_category_id': job_category_id,
                'job_category': DEFAULT_JOB_CATEGORY,
                'company_id': company_id,
                'company_name': company_name,
                'position_name': position_name,
                'position_id': position_id,
                'link': href,
            })
    except:
        continue

print(f"  âœ“ ë¦¬ìŠ¤íŠ¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ: {len(list_data)}ê°œ")

# ë¸Œë¼ìš°ì € ì¢…ë£Œ
driver.quit()
print("  âœ“ ë¸Œë¼ìš°ì € ì¢…ë£Œ")

# 1-2: ìƒì„¸ í˜ì´ì§€ ë³‘ë ¬ í¬ë¡¤ë§
print(f"\n[1-2] ìƒì„¸ í˜ì´ì§€ ë³‘ë ¬ í¬ë¡¤ë§ ({MAX_WORKERS_CRAWL}ê°œ ë™ì‹œ)...")

completed_count = 0

def crawl_detail_page(row_data):
    """ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§"""
    global completed_count
    
    idx = row_data['idx']
    href = row_data['link']
    total = row_data['total']
    
    result = {
        'idx': idx,
        'position': '',
        'content1': '',
        'content2': '',
        'content3': '-',
        'content4': '-',
        'period': '-',
        'skill': ''
    }
    
    if not href:
        return result
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(href, headers=headers, timeout=10)
        
        if response.status_code != 200:
            return result
        
        soup = BeautifulSoup(response.text, 'html.parser')
        next_data_script = soup.find('script', id='__NEXT_DATA__')
        
        if next_data_script:
            try:
                json_data = json.loads(next_data_script.string)
                job_detail = json_data.get('props', {}).get('pageProps', {}).get('jobDetail', {})
                
                result['position'] = job_detail.get('position', '')
                detail = job_detail.get('detail', {})
                
                intro = detail.get('intro', '')
                result['content1'] = intro.replace('\n', ' ').replace('â€¢ ', '').strip() if intro else ''
                
                requirements = detail.get('requirements', '')
                result['content2'] = requirements.replace('\n', ' ').replace('â€¢ ', '').strip() if requirements else ''
                
                preferred = detail.get('preferred', '')
                result['content3'] = preferred.replace('\n', ' ').replace('â€¢ ', '').strip() if preferred else '-'
                
                benefits = detail.get('benefits', '')
                result['content4'] = benefits.replace('\n', ' ').replace('â€¢ ', '').strip() if benefits else '-'
                
                result['period'] = job_detail.get('dueTime', '-') or '-'
                
                skill_tags = job_detail.get('skillTags', [])
                if skill_tags:
                    result['skill'] = '::'.join([tag.get('name', '') for tag in skill_tags if tag.get('name')])
            except:
                pass
    except:
        pass
    
    with progress_lock:
        completed_count += 1
        print(f"\r  [{completed_count}/{total}] ìƒì„¸ í¬ë¡¤ë§ ì¤‘... ({completed_count/total*100:.0f}%)", end='', flush=True)
    
    return result

row_data_list = [{'idx': i, 'link': d['link'], 'total': len(list_data)} for i, d in enumerate(list_data)]

detail_results = []
step1_start = time.time()

with ThreadPoolExecutor(max_workers=MAX_WORKERS_CRAWL) as executor:
    futures = [executor.submit(crawl_detail_page, rd) for rd in row_data_list]
    for future in as_completed(futures):
        detail_results.append(future.result())

detail_results.sort(key=lambda x: x['idx'])

step1_time = time.time() - step1_start
print(f"\n  âœ“ ìƒì„¸ í¬ë¡¤ë§ ì™„ë£Œ! ({step1_time:.1f}ì´ˆ)")

# ê²°ê³¼ í•©ì¹˜ê¸°
df_list = pd.DataFrame(list_data)
df_detail = pd.DataFrame([{k: v for k, v in r.items() if k != 'idx'} for r in detail_results])
df_step1 = pd.concat([df_list, df_detail], axis=1)

step1_file = f"{BASE_PATH}wanted_step1_crawl_{now_str}.xlsx"
df_step1.to_excel(step1_file, index=False, engine='openpyxl')
print(f"  âœ“ STEP 1 ì €ì¥: {step1_file}")

# ============================================
# [STEP 2] OpenAIë¡œ AI ê´€ë ¨ ê³µê³  ë¶„ë¥˜
# ============================================
print("\n" + "=" * 80)
print("[STEP 2/3] AI ê´€ë ¨ ê³µê³  ë¶„ë¥˜ (OpenAI)")
print("=" * 80)

def create_combined_text(row):
    columns = ['position_name', 'position', 'content1', 'content2', 'content3', 'content4']
    texts = []
    for col in columns:
        if col in row and pd.notna(row[col]) and str(row[col]).strip():
            texts.append(str(row[col]).strip())
    return " ".join(texts)

df_step1['combined_text'] = df_step1.apply(create_combined_text, axis=1)

completed_count = 0

def classify_with_openai(task_data):
    """OpenAIë¡œ AI ê³µê³  ë¶„ë¥˜"""
    global completed_count
    
    idx = task_data['idx']
    text = task_data['text']
    total = task_data['total']
    
    result = {'idx': idx, 'classification': 'AIë¹„ê´€ë ¨', 'reason': '', 'summary': ''}
    
    if not text or len(str(text).strip()) < 10:
        result['reason'] = 'ë‚´ìš© ë¶€ì¡±'
        with progress_lock:
            completed_count += 1
            print(f"\r  [{completed_count}/{total}] ë¶„ë¥˜ ì¤‘... ({completed_count/total*100:.0f}%)", end='', flush=True)
        return result
    
    prompt = f"""ì±„ìš© ê³µê³ ë¥¼ ë¶„ì„í•˜ì„¸ìš”:
1. AI ê´€ë ¨ ì§ë¬´ì¸ì§€ íŒë‹¨ (AIê´€ë ¨/AIë¹„ê´€ë ¨)
2. íŒë‹¨ ê·¼ê±° (1-2ë¬¸ì¥)
3. 150ì ì´ë‚´ ìš”ì•½

AI í‚¤ì›Œë“œ: AI, ì¸ê³µì§€ëŠ¥, ë¨¸ì‹ ëŸ¬ë‹, ë”¥ëŸ¬ë‹, LLM, í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§, Agent, RAG, ë¹„ì „ AI, Computer Vision

ê³µê³  ë‚´ìš©:
{text[:2000]}

í˜•ì‹:
ë¶„ë¥˜: [AIê´€ë ¨/AIë¹„ê´€ë ¨]
ê·¼ê±°: [ê·¼ê±°]
ìš”ì•½: [ìš”ì•½]"""
    
    try:
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ì±„ìš© ê³µê³  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        
        result_text = response.choices[0].message.content.strip()
        for line in result_text.split('\n'):
            line = line.strip()
            if line.startswith('ë¶„ë¥˜:'):
                result['classification'] = 'AIê´€ë ¨' if 'AIê´€ë ¨' in line else 'AIë¹„ê´€ë ¨'
            elif line.startswith('ê·¼ê±°:'):
                result['reason'] = line.replace('ê·¼ê±°:', '').strip()
            elif line.startswith('ìš”ì•½:'):
                result['summary'] = line.replace('ìš”ì•½:', '').strip()
    except:
        result['reason'] = 'ë¶„ì„ ì‹¤íŒ¨'
    
    with progress_lock:
        completed_count += 1
        status = "AI" if result['classification'] == 'AIê´€ë ¨' else "-"
        print(f"\r  [{completed_count}/{total}] ë¶„ë¥˜ ì¤‘... ({completed_count/total*100:.0f}%) {status}", end='', flush=True)
    
    return result

print(f"\n[2-1] AI ê³µê³  ë¶„ë¥˜ ì¤‘ ({MAX_WORKERS_OPENAI}ê°œ ë™ì‹œ)...")

task_list = [{'idx': i, 'text': row.get('combined_text', ''), 'total': len(df_step1)} 
             for i, row in df_step1.iterrows()]

step2_start = time.time()
classify_results = []

with ThreadPoolExecutor(max_workers=MAX_WORKERS_OPENAI) as executor:
    futures = [executor.submit(classify_with_openai, task) for task in task_list]
    for future in as_completed(futures):
        classify_results.append(future.result())

classify_results.sort(key=lambda x: x['idx'])

step2_time = time.time() - step2_start
print(f"\n  âœ“ ë¶„ë¥˜ ì™„ë£Œ! ({step2_time:.1f}ì´ˆ)")

# ê²°ê³¼ ì¶”ê°€
df_step1['AI_classification'] = [r['classification'] for r in classify_results]
df_step1['AI_reason'] = [r['reason'] for r in classify_results]
df_step1['summary'] = [r['summary'] for r in classify_results]

# AI ê´€ë ¨ ê³µê³ ë§Œ í•„í„°ë§
df_ai_only = df_step1[df_step1['AI_classification'] == 'AIê´€ë ¨'].copy()

ai_count = len(df_ai_only)
print(f"  âœ“ AIê´€ë ¨: {ai_count}ê°œ ({ai_count/len(df_step1)*100:.1f}%)")

step2_file = f"{BASE_PATH}wanted_step2_classified_{now_str}.xlsx"
df_step1.to_excel(step2_file, index=False, engine='openpyxl')
print(f"  âœ“ STEP 2 ì €ì¥: {step2_file}")

# ============================================
# [STEP 3] ê¸°ì—… ì •ë³´ í¬ë¡¤ë§ (AI ê´€ë ¨ ê³µê³ ë§Œ)
# ============================================
print("\n" + "=" * 80)
print(f"[STEP 3/3] ê¸°ì—… ì •ë³´ í¬ë¡¤ë§ (AI ê´€ë ¨ {len(df_ai_only)}ê°œ)")
print("=" * 80)

completed_count = 0

def crawl_company_info(company_id, company_name, idx, total):
    """ê¸°ì—… ì •ë³´ í¬ë¡¤ë§"""
    global completed_count
    
    result = {
        'idx': idx,
        'í‘œì¤€ì‚°ì—…ë¶„ë¥˜': '',
        'ì—°í˜': '',
        'ë§¤ì¶œì•¡': '',
        'ê³ ìš©ë³´í—˜ê°€ì…ì‚¬ì›ìˆ˜': '',
        'íšŒì‚¬ì†Œê°œ': ''
    }
    
    if pd.isna(company_id):
        return result
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(f"https://www.wanted.co.kr/company/{company_id}", headers=headers, timeout=10)
        
        if response.status_code != 200:
            return result
        
        soup = BeautifulSoup(response.text, 'html.parser')
        next_data_script = soup.find('script', id='__NEXT_DATA__')
        
        if next_data_script:
            try:
                json_data = json.loads(next_data_script.string)
                company_data = json_data.get('props', {}).get('pageProps', {}).get('company', {})
                
                result['íšŒì‚¬ì†Œê°œ'] = company_data.get('description', '')
                
                for item in company_data.get('companyInfoTable', []):
                    label = item.get('label', '')
                    value = item.get('value', '')
                    if label == 'í‘œì¤€ì‚°ì—…ë¶„ë¥˜':
                        result['í‘œì¤€ì‚°ì—…ë¶„ë¥˜'] = value
                    elif label == 'ì—°í˜':
                        result['ì—°í˜'] = value
                    elif label == 'ë§¤ì¶œì•¡':
                        result['ë§¤ì¶œì•¡'] = value
                    elif label == 'ê³ ìš©ë³´í—˜ ê°€ì… ì‚¬ì›ìˆ˜':
                        result['ê³ ìš©ë³´í—˜ê°€ì…ì‚¬ì›ìˆ˜'] = value
            except:
                pass
    except:
        pass
    
    with progress_lock:
        completed_count += 1
        status = "âœ“" if result['íšŒì‚¬ì†Œê°œ'] else "-"
        print(f"\r  [{completed_count}/{total}] ê¸°ì—… í¬ë¡¤ë§ ì¤‘... ({completed_count/total*100:.0f}%) {status}", end='', flush=True)
    
    return result

def analyze_company_with_openai(result, company_name, idx, total):
    """OpenAIë¡œ íšŒì‚¬ì†Œê°œ ë¶„ì„"""
    desc = result.get('íšŒì‚¬ì†Œê°œ', '')
    
    result['íšŒì‚¬ì†Œê°œìš”ì•½'] = ''
    result['ì‚°ì—…ë¶„ì•¼'] = ''
    
    if desc and desc.strip():
        try:
            completion = openai_client.chat.completions.create(
                model='gpt-4o-mini',
                messages=[
                    {"role": "system", "content": "íšŒì‚¬ ì†Œê°œê¸€ì„ 150ì ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”."},
                    {"role": "user", "content": f"[íšŒì‚¬ëª…: {company_name}]\n{desc}"},
                ],
                max_tokens=200,
                temperature=0.3
            )
            result['íšŒì‚¬ì†Œê°œìš”ì•½'] = completion.choices[0].message.content.strip()
        except:
            pass
        
        try:
            completion = openai_client.chat.completions.create(
                model='gpt-4o-mini',
                messages=[
                    {"role": "system", "content": "ì‚°ì—…ë¶„ì•¼ë¥¼ í•œë‘ ë‹¨ì–´ë¡œ ë‹µí•˜ì„¸ìš”. ì˜ˆ: ê²Œì„, ì†Œí”„íŠ¸ì›¨ì–´, í—¬ìŠ¤ì¼€ì–´"},
                    {"role": "user", "content": f"[íšŒì‚¬ëª…: {company_name}]\n{desc}"},
                ],
                max_tokens=16,
                temperature=0
            )
            result['ì‚°ì—…ë¶„ì•¼'] = completion.choices[0].message.content.strip().split('\n')[0]
        except:
            pass
    
    print(f"\r  [OpenAI] {idx+1}/{total} â†’ {result['ì‚°ì—…ë¶„ì•¼']}", end='', flush=True)
    
    return result

if len(df_ai_only) > 0:
    # 3-1: ê¸°ì—… ì •ë³´ í¬ë¡¤ë§
    print(f"\n[3-1] ê¸°ì—… ì •ë³´ í¬ë¡¤ë§ ({MAX_WORKERS_CRAWL}ê°œ ë™ì‹œ)...")
    
    company_id_col = 'company_id'
    step3_start = time.time()
    
    company_results = []
    total = len(df_ai_only)
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS_CRAWL) as executor:
        futures = []
        for idx, (_, row) in enumerate(df_ai_only.iterrows()):
            company_id = row.get(company_id_col, '')
            company_name = row.get('company_name', '')
            future = executor.submit(crawl_company_info, company_id, company_name, idx, total)
            futures.append(future)
        
        for future in as_completed(futures):
            company_results.append(future.result())
    
    company_results.sort(key=lambda x: x['idx'])
    
    crawl_time = time.time() - step3_start
    print(f"\n  âœ“ ê¸°ì—… í¬ë¡¤ë§ ì™„ë£Œ! ({crawl_time:.1f}ì´ˆ)")
    
    # 3-2: OpenAI ë¶„ì„
    print(f"\n[3-2] OpenAI ë¶„ì„ ({MAX_WORKERS_OPENAI}ê°œ ë™ì‹œ)...")
    
    openai_start = time.time()
    final_results = []
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS_OPENAI) as executor:
        futures = []
        for idx, (result, (_, row)) in enumerate(zip(company_results, df_ai_only.iterrows())):
            company_name = row.get('company_name', '')
            future = executor.submit(analyze_company_with_openai, result, company_name, idx, total)
            futures.append((idx, future))
        
        final_results = [None] * len(company_results)
        for idx, future in futures:
            final_results[idx] = future.result()
    
    openai_time = time.time() - openai_start
    print(f"\n  âœ“ OpenAI ë¶„ì„ ì™„ë£Œ! ({openai_time:.1f}ì´ˆ)")
    
    # ê²°ê³¼ ì¶”ê°€
    df_ai_only['í‘œì¤€ì‚°ì—…ë¶„ë¥˜'] = [r['í‘œì¤€ì‚°ì—…ë¶„ë¥˜'] for r in final_results]
    df_ai_only['ì—°í˜'] = [r['ì—°í˜'] for r in final_results]
    df_ai_only['ë§¤ì¶œì•¡'] = [r['ë§¤ì¶œì•¡'] for r in final_results]
    df_ai_only['ê³ ìš©ë³´í—˜ê°€ì…ì‚¬ì›ìˆ˜'] = [r['ê³ ìš©ë³´í—˜ê°€ì…ì‚¬ì›ìˆ˜'] for r in final_results]
    df_ai_only['íšŒì‚¬ì†Œê°œ'] = [r.get('íšŒì‚¬ì†Œê°œ', '') for r in final_results]
    df_ai_only['íšŒì‚¬ì†Œê°œìš”ì•½(OpenAI)'] = [r.get('íšŒì‚¬ì†Œê°œìš”ì•½', '') for r in final_results]
    df_ai_only['ì‚°ì—…ë¶„ì•¼(OpenAI)'] = [r.get('ì‚°ì—…ë¶„ì•¼', '') for r in final_results]

# ============================================
# ìµœì¢… ì €ì¥
# ============================================
print("\n" + "=" * 80)
print("[ìµœì¢… ì €ì¥]")
print("=" * 80)

# ì»¬ëŸ¼ëª… ë³€ê²½
column_rename = {
    'AI_classification': 'AIì—¬ë¶€',
    'AI_reason': 'AIì´ìœ ',
    'job_category': 'ì§ë¬´ë¶„ì•¼',
    'company_name': 'íšŒì‚¬ëª…',
    'position_name': 'í¬ì§€ì…˜ëª…',
    'summary': 'ìš”ì•½',
    'link': 'ë§í¬',
    'position': 'í¬ì§€ì…˜ìƒì„¸',
    'content1': 'ì£¼ìš”ì—…ë¬´',
    'content2': 'ìê²©ìš”ê±´',
    'content3': 'ìš°ëŒ€ì‚¬í•­',
    'content4': 'í˜œíƒ ë° ë³µì§€'
}

# ë¶ˆë²• ë¬¸ì ì œê±°
ILLEGAL_CHARS_RE = re.compile(r'[\x00-\x08\x0b\x0c\x0e-\x1f]')
def clean_illegal_chars(value):
    if isinstance(value, str):
        return ILLEGAL_CHARS_RE.sub('', value)
    return value

# ì „ì²´ ê²°ê³¼ ì €ì¥
df_step1 = df_step1.rename(columns=column_rename)
for col in df_step1.columns:
    if df_step1[col].dtype == 'object':
        df_step1[col] = df_step1[col].apply(clean_illegal_chars)

all_file = f"{BASE_PATH}wanted_all_{now_str}.xlsx"
df_step1.to_excel(all_file, index=False, engine='openpyxl')
print(f"âœ“ ì „ì²´ ê²°ê³¼: {all_file} ({len(df_step1)}ê°œ)")

# AI ê´€ë ¨ + ê¸°ì—…ì •ë³´ ì €ì¥
if len(df_ai_only) > 0:
    df_ai_only = df_ai_only.rename(columns=column_rename)
    for col in df_ai_only.columns:
        if df_ai_only[col].dtype == 'object':
            df_ai_only[col] = df_ai_only[col].apply(clean_illegal_chars)
    
    ai_file = f"{BASE_PATH}wanted_AI_final_{now_str}.xlsx"
    df_ai_only.to_excel(ai_file, index=False, engine='openpyxl')
    print(f"âœ“ AIê´€ë ¨ ê²°ê³¼: {ai_file} ({len(df_ai_only)}ê°œ)")

# ============================================
# ìµœì¢… í†µê³„
# ============================================
total_time = time.time() - total_start_time

print("\n" + "=" * 80)
print("ğŸ“Š ìµœì¢… ê²°ê³¼")
print("=" * 80)
print(f"ì´ ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ ({total_time/60:.1f}ë¶„)")
print(f"")
print(f"[STEP 1] ì±„ìš©ê³µê³  í¬ë¡¤ë§: {len(list_data)}ê°œ")
print(f"[STEP 2] AI ê³µê³  ë¶„ë¥˜: AIê´€ë ¨ {ai_count}ê°œ / ì´ {len(df_step1)}ê°œ ({ai_count/len(df_step1)*100:.1f}%)")
if len(df_ai_only) > 0:
    desc_count = sum(1 for r in final_results if r.get('íšŒì‚¬ì†Œê°œ'))
    print(f"[STEP 3] ê¸°ì—…ì •ë³´ ìˆ˜ì§‘: {desc_count}ê°œ / {len(df_ai_only)}ê°œ")
print("=" * 80)

print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

